{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi there, just wanted to check in and see how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Don't forget about our meeting tomorrow at 10 AM.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can you send me the report by the end of the day?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Happy birthday! Hope you have a fantastic day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Let's catch up over coffee sometime next week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>spam</td>\n",
       "      <td>You've received a new voicemail. Listen to it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your flight has been booked. Check your itiner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your refund is being processed. Track it here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>spam</td>\n",
       "      <td>You've been invited to an exclusive event. RSV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your subscription has been updated. Review the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              email\n",
       "0    ham  Hi there, just wanted to check in and see how ...\n",
       "1    ham  Don't forget about our meeting tomorrow at 10 AM.\n",
       "2    ham  Can you send me the report by the end of the day?\n",
       "3    ham     Happy birthday! Hope you have a fantastic day.\n",
       "4    ham     Let's catch up over coffee sometime next week.\n",
       "..   ...                                                ...\n",
       "87  spam  You've received a new voicemail. Listen to it ...\n",
       "88  spam  Your flight has been booked. Check your itiner...\n",
       "89  spam     Your refund is being processed. Track it here.\n",
       "90  spam  You've been invited to an exclusive event. RSV...\n",
       "91  spam  Your subscription has been updated. Review the...\n",
       "\n",
       "[92 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "email = pd.read_csv('spam_ham_dataset.csv',sep='-',names=['label','email'])\n",
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi want check see',\n",
       " 'forget meet tomorrow',\n",
       " 'send report end day',\n",
       " 'happy birthday hope fantastic day',\n",
       " 'let catch coffee sometime next week',\n",
       " 'please review attach document provide feedback',\n",
       " 'thank help project',\n",
       " 'look forward collaboration new initiative',\n",
       " 'minutes last meet',\n",
       " 'congratulations promotion',\n",
       " 'please confirm attendance event',\n",
       " 'schedule call us pm tomorrow',\n",
       " 'please let know need assistance',\n",
       " 'thank prompt response',\n",
       " 'hope great weekend',\n",
       " 'congratulations lottery',\n",
       " 'reminder lunch meet tomorrow',\n",
       " 'please send update file',\n",
       " 'hope well',\n",
       " 'please find attach invoice reference',\n",
       " 'let schedule call discuss project detail',\n",
       " 'thank cooperation',\n",
       " 'appreciate quick response',\n",
       " 'reschedule meet next week',\n",
       " 'please let know question',\n",
       " 'office next week',\n",
       " 'look forward feedback',\n",
       " 'provide update status project',\n",
       " 'thank information',\n",
       " 'please confirm receipt email',\n",
       " 'get back soon possible',\n",
       " 'hope great holiday',\n",
       " 'please see attach document review',\n",
       " 'thank patience',\n",
       " 'please clarify requirements',\n",
       " 'attend conference next month',\n",
       " 'please let know availability meet',\n",
       " 'appreciate assistance matter',\n",
       " 'hope good day',\n",
       " 'please find attach report review',\n",
       " 'thank understand',\n",
       " 'please provide detail',\n",
       " 'follow next week',\n",
       " 'hope productive week',\n",
       " 'please let know need additional information',\n",
       " 'thank support',\n",
       " 'discuss next meet',\n",
       " 'hope enjoy vacation',\n",
       " 'please see attach presentation reference',\n",
       " 'thank prompt attention matter',\n",
       " 'please send meet minutes',\n",
       " 'available call tomorrow',\n",
       " 'hope great day',\n",
       " 'please let know concern',\n",
       " 'thank cooperation project',\n",
       " 'please review attach proposal',\n",
       " 'touch soon',\n",
       " 'lucky winner click claim prize',\n",
       " 'dear user notice unusual activity account please verify identity secure account',\n",
       " 'important notice account suspend unless update bill information',\n",
       " 'exclusive offer get products use code save checkout',\n",
       " 'order ship track package provide track number',\n",
       " 'subscription expire renew continue enjoy service',\n",
       " 'select free vacation claim trip today',\n",
       " 'account compromise reset password immediately',\n",
       " 'get free iphone limit time offer act fast',\n",
       " 'new message wait click read',\n",
       " 'payment overdue pay avoid late fee',\n",
       " 'choose special discount redeem coupon',\n",
       " 'credit score increase check new score',\n",
       " 'receive gift card click claim reward',\n",
       " 'act get free trial premium service',\n",
       " 'loan application approve click finalize',\n",
       " 'free cruise claim ticket',\n",
       " 'account eligible special upgrade upgrade',\n",
       " 'get exclusive access new product launch sign today',\n",
       " 'opinion matter take survey win prize',\n",
       " 'limit time offer save next purchase',\n",
       " 'friend send gift open',\n",
       " 'new follower see',\n",
       " 'package way track',\n",
       " 'win brand new car enter contest',\n",
       " 'membership expire renew today',\n",
       " 'select special offer miss',\n",
       " 'account need verification verify avoid suspension',\n",
       " 'get free sample new product claim today',\n",
       " 'invoice ready view',\n",
       " 'receive new voicemail listen',\n",
       " 'flight book check itinerary',\n",
       " 'refund process track',\n",
       " 'invite exclusive event rsvp',\n",
       " 'subscription update review change']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer=PorterStemmer()\n",
    "lemmatization= WordNetLemmatizer()\n",
    "corpus=[]\n",
    "for i in range(0,len(email)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',email['email'][i]).lower().split()\n",
    "    stemmWords = [lemmatization.lemmatize(word,pos='v') for word in review if word not in set(stopwords.words('english'))]\n",
    "    stemmWords = ' '.join(stemmWords)\n",
    "    corpus.append(stemmWords)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=10,binary=True,ngram_range=(1,2))\n",
    "values = cv.fit_transform(corpus).toarray()\n",
    "values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
